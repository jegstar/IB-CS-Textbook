# Big O Notation


Big O notation is a key concept in understanding approximately how long it will take to run an algorithm. It shows what we call time complexity, the approximate amount of time that it will take to run. It's probably best to think of this in concrete terms first.

Consider this example. There is a new teacher at a school, Miss O, she needs to move through a list of students and find her student Steven. The way she needs to search through this list of students is one by one. As they are listed in the order of their last names. If there is a list of N students, in the worst case scenario, she will need to go through all of them to find Steven, meaning that she has to make N comparisions to find the student. In the average scenario she needs to check half of the students to find Steven, so she has to make N/2 comparisons. In both of these cases the number of checks that she has to make is connected linearly to the number of students that there are. So in this situation, finding a student in an unordered list, the time she has to spend looking changes linearly based on the number of items. This is written as O(n). This means that as the number of students increases, the number of checks increases __in the order of__ the number of items there are in the search space.
